{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pf5UZs7JWGxi",
    "outputId": "536d4f7e-5ba7-44a8-868d-95875e1d461a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# How to enable Colab GPUs https://colab.research.google.com/notebooks/gpu.ipynb\n",
    "# Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator,\n",
    "# and then re-execute this cell.\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name != '/device:GPU:0':\n",
    "        raise SystemError('GPU device not found')\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# Reduces variance in results but won't eliminate it :-(\n",
    "%env PYTHONHASHSEED=0\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyCv2NuFWGxu"
   },
   "source": [
    "# Title\n",
    "\n",
    "Description ...\n",
    "\n",
    "Refer to previous work?\n",
    "\n",
    "\n",
    "## Import Data\n",
    "\n",
    "Data has been cleaned but may still have issues ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7FRhZV6QWGxx",
    "outputId": "7b495c6c-b13d-4ede-f05c-6ecea2e4a0b5"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    data_loc = \"https://github.com/makeyourownmaker/CambridgeTemperatureModel/blob/master/data/CamUKWeather.csv?raw=true\"\n",
    "else:\n",
    "    data_loc = \"../data/CamUKWeather.csv\"\n",
    "df = pd.read_csv(data_loc, parse_dates = True)\n",
    "\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "print(\"Shape:\")\n",
    "print(df.shape)\n",
    "print(\"\\nInfo:\")\n",
    "print(df.info())\n",
    "print(\"\\nSummary stats:\")\n",
    "display(df.describe())\n",
    "print(\"\\nRaw data:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg7Z2LzpWGxz"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Data Processing\n",
    "\n",
    "The data must be reformatted before ...\n",
    "\n",
    "The following steps are necessary:\n",
    " * Impute missing data where possible\n",
    " * Time conversion\n",
    " * Split data\n",
    " * Normalise data\n",
    " * ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "yzA32Z8IWGxz",
    "outputId": "3eac353e-8496-4cfa-dbff-757257681d51"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ax_DlA4WGyB"
   },
   "source": [
    "\n",
    "From the plots, its worth noting:\n",
    " * ...\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Fortunately ...\n",
    "\n",
    "On an unrelated matter ...\n",
    "\n",
    "Future work:\n",
    " * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oSbcHtRWGyB"
   },
   "source": [
    "---\n",
    "\n",
    "## Metadata\n",
    "\n",
    "Python and Jupyter versions plus modules imported and their version strings. \n",
    "This is the poor man's python equivalent of R's sessionInfo().\n",
    "\n",
    "Code for imported modules and versions adapted from this stackoverflow answer. \n",
    "There are simpler alternatives, such as watermark, but they all require installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YI4Y0ramWGyC"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "print(\"Python version:\")\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(\"\\nIPython version:\")\n",
    "print(IPython.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqT2k2JNWGyC"
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names.  Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name.  You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\":       \"Pillow\",\n",
    "            \"sklearn\":   \"scikit-learn\",\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name != \"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "reqs = pd.DataFrame(requirements, columns = ['name', 'version'])\n",
    "print(\"Imported modules:\")\n",
    "reqs.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBgujFalWGyD"
   },
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWXBP3PzWGyD"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Archival\n",
    "\n",
    "Archive code, markdown, history and formatted notebooks.\n",
    "\n",
    "Assumes all pdf, html, latex etc dependencies are installed.\n",
    "\n",
    "**WARNING** Will overwrite existing files.\n",
    "\n",
    "Notebook name is hardcoded below because the alternative is ghastly globs of unreliable javascript or external ipython libraries I'd prefer to avoid installing :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcGuysl1WGyE"
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "notebook = \"keras_mlp_fcn_resnet_time_series.ipynb\"\n",
    "# !jupyter nbconvert --to script {notebook}\n",
    "# !jupyter nbconvert --execute --to html {notebook}\n",
    "# !jupyter nbconvert --execute --to pdf {notebook}\n",
    "# !jupyter nbconvert --to pdf {notebook}\n",
    "\n",
    "%rm history.txt\n",
    "%history -f history.txt\n",
    "\n",
    "!jupyter nbconvert --to python {notebook}\n",
    "sleep(5)\n",
    "!jupyter nbconvert --to markdown {notebook}\n",
    "sleep(5)\n",
    "!jupyter nbconvert --to html {notebook}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "keras_mlp_fcn_resnet_time_series.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
